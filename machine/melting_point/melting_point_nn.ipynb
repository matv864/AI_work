{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3ea80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import numpy as np  # для чисел и вычислений\n",
    "import pandas as pd  # для таблиц (как Excel в Python)\n",
    "import matplotlib.pyplot as plt  # для графиков\n",
    "import seaborn as sns  # для красивых графиков\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from clearing import DatasetCleaner  # soft link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453dfd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39bbba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_FOLDER = \"/home/arman/it/AI_work/machine/melting_point\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f741bf7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающих данных: (2662, 427)\n",
      "Размер тестовых данных: (666, 426)\n",
      "Первые 3 строки обучающих данных:\n",
      "     id                       SMILES      Tm  Group 1  Group 2  Group 3  \\\n",
      "0  2175        FC1=C(F)C(F)(F)C1(F)F  213.15        0        0        0   \n",
      "1  1222  c1ccc2c(c1)ccc3Nc4ccccc4c23  407.15        0        0        0   \n",
      "2  2994          CCN1C(C)=Nc2ccccc12  324.15        2        1        0   \n",
      "\n",
      "   Group 4  Group 5  Group 6  Group 7  ...  Group 415  Group 416  Group 417  \\\n",
      "0        0        0        0        0  ...          0          0          0   \n",
      "1        0        0        0        0  ...          0          0          0   \n",
      "2        0        0        0        0  ...          0          0          0   \n",
      "\n",
      "   Group 418  Group 419  Group 420  Group 421  Group 422  Group 423  Group 424  \n",
      "0          0          0          0          0          0          0          0  \n",
      "1          0          0          0          0          0          0          0  \n",
      "2          0          0          0          0          0          0          0  \n",
      "\n",
      "[3 rows x 427 columns]\n",
      "Колонки в данных:\n",
      "['id', 'SMILES', 'Tm', 'Group 1', 'Group 2', 'Group 3', 'Group 4', 'Group 5', 'Group 6', 'Group 7'] ...\n"
     ]
    }
   ],
   "source": [
    "# Читаем файлы\n",
    "train_data = pd.read_csv(f\"{MAIN_FOLDER}/data/train.csv\")  # данные для обучения\n",
    "test_data = pd.read_csv(f\"{MAIN_FOLDER}/data/test.csv\")  # данные для теста\n",
    "sample_sub = pd.read_csv(f\"{MAIN_FOLDER}/data/sample_submission.csv\")  # шаблон для ответа\n",
    "\n",
    "# Посмотрим что у нас есть\n",
    "print(f\"Размер обучающих данных: {train_data.shape}\")\n",
    "print(f\"Размер тестовых данных: {test_data.shape}\")\n",
    "print(\"Первые 3 строки обучающих данных:\")\n",
    "print(train_data.head(3))\n",
    "print(\"Колонки в данных:\")\n",
    "print(train_data.columns.tolist()[:10], \"...\")  # первые 10 колонок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a9aaf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaner = DatasetCleaner(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aa05593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE Group 12 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 28 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 46 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 67 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 73 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 74 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 75 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 84 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 85 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 88 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 90 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 101 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 102 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 104 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 150 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 152 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 155 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 158 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 160 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 167 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 183 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 194 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 198 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 206 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 207 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 208 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 209 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 212 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 213 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 214 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 215 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 216 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 217 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 218 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 245 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 247 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 248 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 250 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 252 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 253 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 264 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 280 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 281 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 282 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 285 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 294 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 303 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 306 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 307 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 308 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 309 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 312 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 313 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 316 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 317 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 340 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 342 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 345 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 347 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 348 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 349 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 350 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 352 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 355 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 356 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 357 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 358 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 360 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 363 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 371 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 376 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 377 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 383 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 384 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 385 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 390 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 397 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 399 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 411 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 413 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 417 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 419 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 420 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 421 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 422 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 423 (np.int64(0), np.int64(2662), 2662)\n",
      "DELETE Group 424 (np.int64(0), np.int64(2662), 2662)\n"
     ]
    }
   ],
   "source": [
    "cols_to_remove = [\"SMILES\"]\n",
    "\n",
    "for col in train_cleaner.current_df.columns.to_list():\n",
    "    t = train_cleaner.count_missing_and_zeros(column=col)\n",
    "    if t[1] == t[2]:\n",
    "        cols_to_remove.append(col)\n",
    "        print(\"DELETE\", col, t)\n",
    "# нулей нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5df273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SMILES', 'Group 12', 'Group 28', 'Group 46', 'Group 67', 'Group 73', 'Group 74', 'Group 75', 'Group 84', 'Group 85', 'Group 88', 'Group 90', 'Group 101', 'Group 102', 'Group 104', 'Group 150', 'Group 152', 'Group 155', 'Group 158', 'Group 160', 'Group 167', 'Group 183', 'Group 194', 'Group 198', 'Group 206', 'Group 207', 'Group 208', 'Group 209', 'Group 212', 'Group 213', 'Group 214', 'Group 215', 'Group 216', 'Group 217', 'Group 218', 'Group 245', 'Group 247', 'Group 248', 'Group 250', 'Group 252', 'Group 253', 'Group 264', 'Group 280', 'Group 281', 'Group 282', 'Group 285', 'Group 294', 'Group 303', 'Group 306', 'Group 307', 'Group 308', 'Group 309', 'Group 312', 'Group 313', 'Group 316', 'Group 317', 'Group 340', 'Group 342', 'Group 345', 'Group 347', 'Group 348', 'Group 349', 'Group 350', 'Group 352', 'Group 355', 'Group 356', 'Group 357', 'Group 358', 'Group 360', 'Group 363', 'Group 371', 'Group 376', 'Group 377', 'Group 383', 'Group 384', 'Group 385', 'Group 390', 'Group 397', 'Group 399', 'Group 411', 'Group 413', 'Group 417', 'Group 419', 'Group 420', 'Group 421', 'Group 422', 'Group 423', 'Group 424']\n"
     ]
    }
   ],
   "source": [
    "print(cols_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df843509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Group 1</th>\n",
       "      <th>Group 2</th>\n",
       "      <th>Group 3</th>\n",
       "      <th>Group 4</th>\n",
       "      <th>Group 5</th>\n",
       "      <th>Group 6</th>\n",
       "      <th>Group 7</th>\n",
       "      <th>...</th>\n",
       "      <th>Group 415</th>\n",
       "      <th>Group 416</th>\n",
       "      <th>Group 417</th>\n",
       "      <th>Group 418</th>\n",
       "      <th>Group 419</th>\n",
       "      <th>Group 420</th>\n",
       "      <th>Group 421</th>\n",
       "      <th>Group 422</th>\n",
       "      <th>Group 423</th>\n",
       "      <th>Group 424</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 427 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, SMILES, Tm, Group 1, Group 2, Group 3, Group 4, Group 5, Group 6, Group 7, Group 8, Group 9, Group 10, Group 11, Group 12, Group 13, Group 14, Group 15, Group 16, Group 17, Group 18, Group 19, Group 20, Group 21, Group 22, Group 23, Group 24, Group 25, Group 26, Group 27, Group 28, Group 29, Group 30, Group 31, Group 32, Group 33, Group 34, Group 35, Group 36, Group 37, Group 38, Group 39, Group 40, Group 41, Group 42, Group 43, Group 44, Group 45, Group 46, Group 47, Group 48, Group 49, Group 50, Group 51, Group 52, Group 53, Group 54, Group 55, Group 56, Group 57, Group 58, Group 59, Group 60, Group 61, Group 62, Group 63, Group 64, Group 65, Group 66, Group 67, Group 68, Group 69, Group 70, Group 71, Group 72, Group 73, Group 74, Group 75, Group 76, Group 77, Group 78, Group 79, Group 80, Group 81, Group 82, Group 83, Group 84, Group 85, Group 86, Group 87, Group 88, Group 89, Group 90, Group 91, Group 92, Group 93, Group 94, Group 95, Group 96, Group 97, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 427 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaner.find_duplicates()\n",
    "# дубликатов нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f151273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Group 1</th>\n",
       "      <th>Group 2</th>\n",
       "      <th>Group 3</th>\n",
       "      <th>Group 4</th>\n",
       "      <th>Group 5</th>\n",
       "      <th>Group 6</th>\n",
       "      <th>Group 7</th>\n",
       "      <th>Group 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Group 406</th>\n",
       "      <th>Group 407</th>\n",
       "      <th>Group 408</th>\n",
       "      <th>Group 409</th>\n",
       "      <th>Group 410</th>\n",
       "      <th>Group 412</th>\n",
       "      <th>Group 414</th>\n",
       "      <th>Group 415</th>\n",
       "      <th>Group 416</th>\n",
       "      <th>Group 418</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2175</td>\n",
       "      <td>213.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1222</td>\n",
       "      <td>407.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2994</td>\n",
       "      <td>324.15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1704</td>\n",
       "      <td>351.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2526</td>\n",
       "      <td>126.15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 339 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id      Tm  Group 1  Group 2  Group 3  Group 4  Group 5  Group 6  \\\n",
       "0  2175  213.15        0        0        0        0        0        0   \n",
       "1  1222  407.15        0        0        0        0        0        0   \n",
       "2  2994  324.15        2        1        0        0        0        0   \n",
       "3  1704  351.15        1        0        0        0        0        0   \n",
       "4  2526  126.15        2        3        0        0        0        0   \n",
       "\n",
       "   Group 7  Group 8  ...  Group 406  Group 407  Group 408  Group 409  \\\n",
       "0        0        0  ...          0          0          0          0   \n",
       "1        0        0  ...          0          0          0          0   \n",
       "2        0        0  ...          0          0          0          0   \n",
       "3        0        0  ...          0          0          0          0   \n",
       "4        0        0  ...          0          0          0          0   \n",
       "\n",
       "   Group 410  Group 412  Group 414  Group 415  Group 416  Group 418  \n",
       "0          0          0          0          0          0          0  \n",
       "1          0          1          0          0          0          0  \n",
       "2          0          0          0          0          0          0  \n",
       "3          0          0          0          0          0          0  \n",
       "4          0          0          0          0          0          0  \n",
       "\n",
       "[5 rows x 339 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cols_to_remove:\n",
    "    train_cleaner.remove_row_or_column(column=col)\n",
    "train_cleaner.current_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5f369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_algorithm(df):\n",
    "    df_cleaner = DatasetCleaner(df)\n",
    "    for col in cols_to_remove:\n",
    "        df_cleaner.remove_row_or_column(column=col)\n",
    "    return df_cleaner.current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e61bb840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 ['SMILES', 'Group 12', 'Group 28', 'Group 46', 'Group 67', 'Group 73', 'Group 74', 'Group 75', 'Group 84', 'Group 85', 'Group 88', 'Group 90', 'Group 101', 'Group 102', 'Group 104', 'Group 150', 'Group 152', 'Group 155', 'Group 158', 'Group 160', 'Group 167', 'Group 183', 'Group 194', 'Group 198', 'Group 206', 'Group 207', 'Group 208', 'Group 209', 'Group 212', 'Group 213', 'Group 214', 'Group 215', 'Group 216', 'Group 217', 'Group 218', 'Group 245', 'Group 247', 'Group 248', 'Group 250', 'Group 252', 'Group 253', 'Group 264', 'Group 280', 'Group 281', 'Group 282', 'Group 285', 'Group 294', 'Group 303', 'Group 306', 'Group 307', 'Group 308', 'Group 309', 'Group 312', 'Group 313', 'Group 316', 'Group 317', 'Group 340', 'Group 342', 'Group 345', 'Group 347', 'Group 348', 'Group 349', 'Group 350', 'Group 352', 'Group 355', 'Group 356', 'Group 357', 'Group 358', 'Group 360', 'Group 363', 'Group 371', 'Group 376', 'Group 377', 'Group 383', 'Group 384', 'Group 385', 'Group 390', 'Group 397', 'Group 399', 'Group 411', 'Group 413', 'Group 417', 'Group 419', 'Group 420', 'Group 421', 'Group 422', 'Group 423', 'Group 424']\n"
     ]
    }
   ],
   "source": [
    "print(len(cols_to_remove), cols_to_remove)\n",
    "train_cleaner.save_to_csv(f\"{MAIN_FOLDER}/data/prepared_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3104100",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(f\"{MAIN_FOLDER}/data/prepared_train.csv\")  # данные для обучения\n",
    "test_data = pd.read_csv(f\"{MAIN_FOLDER}/data/test.csv\")  # данные для теста\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03e548f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "features = list(set(train_data.columns.to_list()) - set(cols_to_remove) - {\"id\", \"Tm\"})\n",
    "X = train_data[features].values\n",
    "y = train_data['Tm'].values\n",
    "\n",
    "# Split into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "# Prepare test data\n",
    "X_test = test_data[features].values\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1f7e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Group 1', 'Group 10', 'Group 100', 'Group 103', 'Group 105', 'Group 106', 'Group 107', 'Group 108', 'Group 109', 'Group 11', 'Group 110', 'Group 111', 'Group 112', 'Group 113', 'Group 114', 'Group 115', 'Group 116', 'Group 117', 'Group 118', 'Group 119', 'Group 120', 'Group 121', 'Group 122', 'Group 123', 'Group 124', 'Group 125', 'Group 126', 'Group 127', 'Group 128', 'Group 129', 'Group 13', 'Group 130', 'Group 131', 'Group 132', 'Group 133', 'Group 134', 'Group 135', 'Group 136', 'Group 137', 'Group 138', 'Group 139', 'Group 14', 'Group 140', 'Group 141', 'Group 142', 'Group 143', 'Group 144', 'Group 145', 'Group 146', 'Group 147', 'Group 148', 'Group 149', 'Group 15', 'Group 151', 'Group 153', 'Group 154', 'Group 156', 'Group 157', 'Group 159', 'Group 16', 'Group 161', 'Group 162', 'Group 163', 'Group 164', 'Group 165', 'Group 166', 'Group 168', 'Group 169', 'Group 17', 'Group 170', 'Group 171', 'Group 172', 'Group 173', 'Group 174', 'Group 175', 'Group 176', 'Group 177', 'Group 178', 'Group 179', 'Group 18', 'Group 180', 'Group 181', 'Group 182', 'Group 184', 'Group 185', 'Group 186', 'Group 187', 'Group 188', 'Group 189', 'Group 19', 'Group 190', 'Group 191', 'Group 192', 'Group 193', 'Group 195', 'Group 196', 'Group 197', 'Group 199', 'Group 2', 'Group 20', 'Group 200', 'Group 201', 'Group 202', 'Group 203', 'Group 204', 'Group 205', 'Group 21', 'Group 210', 'Group 211', 'Group 219', 'Group 22', 'Group 220', 'Group 221', 'Group 222', 'Group 223', 'Group 224', 'Group 225', 'Group 226', 'Group 227', 'Group 228', 'Group 229', 'Group 23', 'Group 230', 'Group 231', 'Group 232', 'Group 233', 'Group 234', 'Group 235', 'Group 236', 'Group 237', 'Group 238', 'Group 239', 'Group 24', 'Group 240', 'Group 241', 'Group 242', 'Group 243', 'Group 244', 'Group 246', 'Group 249', 'Group 25', 'Group 251', 'Group 254', 'Group 255', 'Group 256', 'Group 257', 'Group 258', 'Group 259', 'Group 26', 'Group 260', 'Group 261', 'Group 262', 'Group 263', 'Group 265', 'Group 266', 'Group 267', 'Group 268', 'Group 269', 'Group 27', 'Group 270', 'Group 271', 'Group 272', 'Group 273', 'Group 274', 'Group 275', 'Group 276', 'Group 277', 'Group 278', 'Group 279', 'Group 283', 'Group 284', 'Group 286', 'Group 287', 'Group 288', 'Group 289', 'Group 29', 'Group 290', 'Group 291', 'Group 292', 'Group 293', 'Group 295', 'Group 296', 'Group 297', 'Group 298', 'Group 299', 'Group 3', 'Group 30', 'Group 300', 'Group 301', 'Group 302', 'Group 304', 'Group 305', 'Group 31', 'Group 310', 'Group 311', 'Group 314', 'Group 315', 'Group 318', 'Group 319', 'Group 32', 'Group 320', 'Group 321', 'Group 322', 'Group 323', 'Group 324', 'Group 325', 'Group 326', 'Group 327', 'Group 328', 'Group 329', 'Group 33', 'Group 330', 'Group 331', 'Group 332', 'Group 333', 'Group 334', 'Group 335', 'Group 336', 'Group 337', 'Group 338', 'Group 339', 'Group 34', 'Group 341', 'Group 343', 'Group 344', 'Group 346', 'Group 35', 'Group 351', 'Group 353', 'Group 354', 'Group 359', 'Group 36', 'Group 361', 'Group 362', 'Group 364', 'Group 365', 'Group 366', 'Group 367', 'Group 368', 'Group 369', 'Group 37', 'Group 370', 'Group 372', 'Group 373', 'Group 374', 'Group 375', 'Group 378', 'Group 379', 'Group 38', 'Group 380', 'Group 381', 'Group 382', 'Group 386', 'Group 387', 'Group 388', 'Group 389', 'Group 39', 'Group 391', 'Group 392', 'Group 393', 'Group 394', 'Group 395', 'Group 396', 'Group 398', 'Group 4', 'Group 40', 'Group 400', 'Group 401', 'Group 402', 'Group 403', 'Group 404', 'Group 405', 'Group 406', 'Group 407', 'Group 408', 'Group 409', 'Group 41', 'Group 410', 'Group 412', 'Group 414', 'Group 415', 'Group 416', 'Group 418', 'Group 42', 'Group 43', 'Group 44', 'Group 45', 'Group 47', 'Group 48', 'Group 49', 'Group 5', 'Group 50', 'Group 51', 'Group 52', 'Group 53', 'Group 54', 'Group 55', 'Group 56', 'Group 57', 'Group 58', 'Group 59', 'Group 6', 'Group 60', 'Group 61', 'Group 62', 'Group 63', 'Group 64', 'Group 65', 'Group 66', 'Group 68', 'Group 69', 'Group 7', 'Group 70', 'Group 71', 'Group 72', 'Group 76', 'Group 77', 'Group 78', 'Group 79', 'Group 8', 'Group 80', 'Group 81', 'Group 82', 'Group 83', 'Group 86', 'Group 87', 'Group 89', 'Group 9', 'Group 91', 'Group 92', 'Group 93', 'Group 94', 'Group 95', 'Group 96', 'Group 97', 'Group 98', 'Group 99']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be06b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class MeltingPointDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = MeltingPointDataset(X_train, y_train)\n",
    "val_dataset = MeltingPointDataset(X_val, y_val)\n",
    "test_dataset = MeltingPointDataset(X_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b124e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural Network\n",
    "class MeltingPointNet(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(MeltingPointNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, optimizer\n",
    "input_size = X_train.shape[1]\n",
    "model = MeltingPointNet(input_size)\n",
    "criterion = nn.L1Loss()  # MAE loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "559b8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Train MAE: 276.7826, Val MAE: 278.3929\n",
      "Epoch 2/30, Train MAE: 274.4177, Val MAE: 275.4831\n",
      "Epoch 3/30, Train MAE: 270.9923, Val MAE: 270.7485\n",
      "Epoch 4/30, Train MAE: 265.8868, Val MAE: 263.4540\n",
      "Epoch 5/30, Train MAE: 258.9938, Val MAE: 255.8448\n",
      "Epoch 6/30, Train MAE: 250.4903, Val MAE: 245.9916\n",
      "Epoch 7/30, Train MAE: 240.4913, Val MAE: 233.1602\n",
      "Epoch 8/30, Train MAE: 228.5797, Val MAE: 222.2787\n",
      "Epoch 9/30, Train MAE: 215.1889, Val MAE: 206.1343\n",
      "Epoch 10/30, Train MAE: 200.4415, Val MAE: 189.9939\n",
      "Epoch 11/30, Train MAE: 184.0193, Val MAE: 174.5872\n",
      "Epoch 12/30, Train MAE: 166.7946, Val MAE: 157.1128\n",
      "Epoch 13/30, Train MAE: 148.9651, Val MAE: 141.1446\n",
      "Epoch 14/30, Train MAE: 130.3388, Val MAE: 125.4504\n",
      "Epoch 15/30, Train MAE: 113.1321, Val MAE: 102.6895\n",
      "Epoch 16/30, Train MAE: 96.4539, Val MAE: 85.6343\n",
      "Epoch 17/30, Train MAE: 80.0286, Val MAE: 75.8751\n",
      "Epoch 18/30, Train MAE: 66.9681, Val MAE: 60.9732\n",
      "Epoch 19/30, Train MAE: 58.7969, Val MAE: 55.6933\n",
      "Epoch 20/30, Train MAE: 50.9253, Val MAE: 44.9117\n",
      "Epoch 21/30, Train MAE: 47.2835, Val MAE: 44.4603\n",
      "Epoch 22/30, Train MAE: 45.9221, Val MAE: 40.8117\n",
      "Epoch 23/30, Train MAE: 42.7332, Val MAE: 40.4450\n",
      "Epoch 24/30, Train MAE: 41.3574, Val MAE: 39.8243\n",
      "Epoch 25/30, Train MAE: 40.3215, Val MAE: 39.3573\n",
      "Epoch 26/30, Train MAE: 39.9383, Val MAE: 37.6771\n",
      "Epoch 27/30, Train MAE: 40.1523, Val MAE: 37.7514\n",
      "Epoch 28/30, Train MAE: 39.8101, Val MAE: 38.8983\n",
      "Epoch 29/30, Train MAE: 39.1959, Val MAE: 37.9316\n",
      "Epoch 30/30, Train MAE: 37.6427, Val MAE: 37.9497\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 30\n",
    "best_val_mae = float('inf')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.squeeze(), y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * len(X_batch)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_batch)\n",
    "            val_loss += loss.item() * len(X_batch)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    if val_loss < best_val_mae:\n",
    "        best_val_mae = val_loss\n",
    "        torch.save(model.state_dict(), f'{MAIN_FOLDER}/data/best_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train MAE: {train_loss:.4f}, Val MAE: {val_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89d1e32d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load best model\n",
    "model.load_state_dict(torch.load(f'{MAIN_FOLDER}/data/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1201d721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        outputs = model(X_batch)\n",
    "        predictions.extend(outputs.squeeze().cpu().numpy())\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_data['id'],\n",
    "    'Tm': predictions\n",
    "})\n",
    "submission.to_csv(f'{MAIN_FOLDER}/data/nn_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
