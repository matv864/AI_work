{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e4014ad",
   "metadata": {},
   "source": [
    "## ЛАБОРАТОРНАЯ РАБОТА №10.\n",
    "## НАИВНЫЙ БАЙЕСОВСКИЙ КЛАССИФИКАТОР\n",
    "#### по дисциплине «Математическая статистика»\n",
    "Направление подготовки 01.03.02 Прикладная математика и информатика\n",
    "Очной формы обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8438b90f",
   "metadata": {},
   "source": [
    "выполнил: студент группы Б9123-01.03.02ии\n",
    "\n",
    "Иванов Матвей Олегович\n",
    "\n",
    "принял: Деревягин Андрей Алексеевич"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06acc1a6",
   "metadata": {},
   "source": [
    "# Математическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82187a02",
   "metadata": {},
   "source": [
    "### Наивный Байесовский классификатор"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e50af8",
   "metadata": {},
   "source": [
    "Наивный Байесовский классификатор основан на теореме Байеса. Для нового объекта с признаками\n",
    "$x = (x_1, x_2, \\cdots, x_m)$ условная вероятность принадлежности к классу $y_k$ вычисляется как:\n",
    "$$p_{Y|X}(y_k|x) = \\frac{p_Y(y_k)*p_{X|Y}(x|y_k)}{p_X(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79852e5",
   "metadata": {},
   "source": [
    "Для вычисления совместной функции вероятности предположим, что признаки независимы в\n",
    "совокупности. И так как знаменатель $p_X(x)$ одинаков для всех классов $y_k$ , он не влияет на результат\n",
    "выбора наиболее вероятного класса. Поэтому для классификации достаточно максимизировать\n",
    "числитель:\n",
    "$$y = \\argmax_{y_k} (\\widehat{p}_Y(y_k) * \\prod^{n}_{i=1} \\widehat{p}_{X_i|Y(x_i|y_k)})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dfee8f",
   "metadata": {},
   "source": [
    "Можно использовать логарифмы, предполагая независимость признаков. Тогда итоговый вид\n",
    "модели:\n",
    "$$y = \\argmax_{y_k} (\\log(\\widehat{p}_Y(y_k)) + \\sum^{m}_{i=1} \\log(\\widehat{p}_{X_i|Y(x_i|y_k)}))$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa6e959",
   "metadata": {},
   "source": [
    "где $\\widehat{p}_{Y_i}(y)$ - относительная частота значения $x у$ признака $Y_i$ . $\\widehat{p}_{X_i|Y}(x|y)$ - относительная частота\n",
    "значения $x у$ признака $X_i$ среди объектов класса $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b658da",
   "metadata": {},
   "source": [
    "### Оценка вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b2b81",
   "metadata": {},
   "source": [
    "Для непрерывных признаков предполагается нормальное распределение, и вероятность заменяется\n",
    "плотностью нормального распределения:\n",
    "$$f_{X_i|Y}(x_i|y_k) = \\frac{1}{\\sqrt{2\\pi}σ_{ik}}e^{-\\frac{(x_i - µ_{ik})^2}{2σ^2_{ik}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857bd5f6",
   "metadata": {},
   "source": [
    "где $µ_{ik}$ — среднее арифметическое, а $σ_{ik}$ — среднеквадратическое отклонение значений признака\n",
    "$X_i$ для объектов класса $y_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cf13f",
   "metadata": {},
   "source": [
    "Для дискретных признаков $p_{X_i|Y}(x_i|y_k)$ оценка проводится как относительная частота значения\n",
    "$x_i$ признака $X_i$ среди объектов класса $y_k$. Чтобы исключить нулевые вероятности, используется\n",
    "сглаживание: к числителю и знаменателю добавляется 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7756170a",
   "metadata": {},
   "source": [
    "# листинг кода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9837d908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#необходимые импорты\n",
    "import numpy as np #библиотека для работы с массивами\n",
    "import scipy.stats as sps #пакет со статистикой для плотности вероятностей нормального распределения\n",
    "from sklearn.metrics import accuracy_score #функция вычисления доли правильно предсказанных классов\n",
    "from sklearn.model_selection import train_test_split #функция разбиения выборки на тренировочную и тестовую\n",
    "from sklearn.naive_bayes import GaussianNB #библиотечный классификатор для непрерывных признаков\n",
    "from sklearn.naive_bayes import MultinomialNB #библиотечный классификатор для дискретных признаков\n",
    "from sklearn.datasets import load_iris, load_digits #датасет ирисы фишера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108ee5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBias:\n",
    "    def __init__(self, discrete_flags: list[bool]):\n",
    "        self.discrete_flags: np.ndarray[bool] = np.array(discrete_flags)\n",
    "        self.all_classes: np.ndarray[int]\n",
    "        self.class_probs: np.ndarray[float]\n",
    "        self.feature_params: dict[int, np.ndarray[dict[int, float] | tuple[float, float]]] = {}\n",
    "\n",
    "    def fit(self, X: np.ndarray[np.ndarray[int]], y: np.ndarray[int]):\n",
    "        self.all_classes = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Вычисляем априорные вероятности классов\n",
    "        self.class_probs = np.array([np.mean(np.array(y == c, dtype=np.int8)) for c in self.all_classes])\n",
    "        \n",
    "        # Для каждого класса и каждого признака сохраняем параметры распределения\n",
    "        for i, c in enumerate(self.all_classes):\n",
    "            class_mask = np.array(y == c)\n",
    "            class_data = X[class_mask]  # только те записи, который имеют y=c\n",
    "            self.feature_params[c] = []\n",
    "            \n",
    "            for feature_i in range(n_features):\n",
    "                feature_data = class_data[:, feature_i]  # забираем фичу\n",
    "                is_discrete_feature = self.discrete_flags[feature_i]\n",
    "                \n",
    "                if is_discrete_feature:\n",
    "                    # дискретные\n",
    "                    values, counts = np.unique(feature_data, return_counts=True)\n",
    "                    prob_dict = {v: c/len(feature_data) for v, c in zip(values, counts)}\n",
    "                    self.feature_params[c].append(prob_dict)\n",
    "                else:\n",
    "                    # непрерывные\n",
    "                    mean = np.mean(feature_data)\n",
    "                    std = np.std(feature_data)\n",
    "                    self.feature_params[c].append((mean, std))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            class_scores = []\n",
    "\n",
    "            for i, c in enumerate(self.all_classes):\n",
    "                prob = self.class_probs[i]\n",
    "\n",
    "                for feature in range(len(sample)):\n",
    "                    if self.discrete_flags[feature]:\n",
    "                        # дискретные\n",
    "                        prob_dict = self.feature_params[c][feature]\n",
    "                        value = sample[feature]\n",
    "                        prob *= prob_dict.get(value, 1e-10)\n",
    "                    else:\n",
    "                        # непрерывные\n",
    "                        mean, std = self.feature_params[c][feature]\n",
    "                        prob *= sps.norm.pdf(sample[feature], mean, std)\n",
    "\n",
    "                class_scores.append(prob)\n",
    "\n",
    "            predicted_class = self.all_classes[np.argmax(class_scores)]\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd2fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBiasLog:\n",
    "    def __init__(self, discrete_flags: list[bool]):\n",
    "        self.discrete_flags: np.ndarray[bool] = np.array(discrete_flags)\n",
    "        self.all_classes: np.ndarray[int]\n",
    "        self.class_probs: np.ndarray[float]\n",
    "        self.feature_params: dict[int, np.ndarray[dict[int, float] | tuple[float, float]]] = {}\n",
    "\n",
    "    def fit(self, X: np.ndarray[np.ndarray[int]], y: np.ndarray[int]):\n",
    "        self.all_classes = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "        \n",
    "        # Вычисляем априорные вероятности классов\n",
    "        self.class_probs = np.array([np.mean(np.array(y == c, dtype=np.int8)) for c in self.all_classes])\n",
    "        \n",
    "        # Для каждого класса и каждого признака сохраняем параметры распределения\n",
    "        for i, c in enumerate(self.all_classes):\n",
    "            class_mask = np.array(y == c)\n",
    "            class_data = X[class_mask]  # только те записи, который имеют y=c\n",
    "            self.feature_params[c] = []\n",
    "            \n",
    "            for feature_i in range(n_features):\n",
    "                feature_data = class_data[:, feature_i]  # забираем фичу\n",
    "                is_discrete_feature = self.discrete_flags[feature_i]\n",
    "                \n",
    "                if is_discrete_feature:\n",
    "                    # дискретные\n",
    "                    values, counts = np.unique(feature_data, return_counts=True)\n",
    "                    prob_dict = {v: c/len(feature_data) for v, c in zip(values, counts)}\n",
    "                    self.feature_params[c].append(prob_dict)\n",
    "                else:\n",
    "                    # непрерывные\n",
    "                    mean = np.mean(feature_data)\n",
    "                    std = np.std(feature_data)\n",
    "                    self.feature_params[c].append((mean, std))\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for sample in X:\n",
    "            class_scores = []\n",
    "\n",
    "            for i, c in enumerate(self.all_classes):\n",
    "                prob = np.log(self.class_probs[i])\n",
    "\n",
    "                for feature in range(len(sample)):\n",
    "                    if self.discrete_flags[feature]:\n",
    "                        # дискретные\n",
    "                        prob_dict = self.feature_params[c][feature]\n",
    "                        value = sample[feature]\n",
    "                        prob += np.log(prob_dict.get(value, 1e-10))\n",
    "                    else:\n",
    "                        # непрерывные\n",
    "                        mean, std = self.feature_params[c][feature]\n",
    "                        prob += np.log(sps.norm.pdf(sample[feature], mean, std))\n",
    "\n",
    "                class_scores.append(prob)\n",
    "\n",
    "            predicted_class = self.all_classes[np.argmax(class_scores)]\n",
    "            predictions.append(predicted_class)\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9701546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нашей реализации: 0.9600\n",
      "Точность GaussianNB: 0.9600\n"
     ]
    }
   ],
   "source": [
    "# проверка работы с непрерывными значениями\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "discrete_flags = [False, False, False, False]\n",
    "\n",
    "our_model = NaiveBias(discrete_flags)\n",
    "our_model.fit(X_train, y_train)\n",
    "\n",
    "our_predictions = our_model.predict(X_test)\n",
    "our_accuracy = accuracy_score(y_test, our_predictions)\n",
    "print(f\"Точность нашей реализации: {our_accuracy:.4f}\")\n",
    "\n",
    "lib_model = GaussianNB()\n",
    "lib_model.fit(X_train, y_train)\n",
    "lib_predictions = lib_model.predict(X_test)\n",
    "lib_accuracy = accuracy_score(y_test, lib_predictions)\n",
    "print(f\"Точность GaussianNB: {lib_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ca3715e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность нашей реализации: 0.7880\n",
      "Точность MultinomialNB: 0.8881\n"
     ]
    }
   ],
   "source": [
    "# проверка работы с дискретными значениями\n",
    "\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)\n",
    "\n",
    "discrete_flags = [True for _ in range(64)]\n",
    "\n",
    "\n",
    "our_model = NaiveBias(discrete_flags)\n",
    "our_model.fit(X_train, y_train)\n",
    "\n",
    "our_predictions = our_model.predict(X_test)\n",
    "our_accuracy = accuracy_score(y_test, our_predictions)\n",
    "print(f\"Точность нашей реализации: {our_accuracy:.4f}\")\n",
    "\n",
    "lib_model = MultinomialNB()\n",
    "lib_model.fit(X_train, y_train)\n",
    "lib_predictions = lib_model.predict(X_test)\n",
    "lib_accuracy = accuracy_score(y_test, lib_predictions)\n",
    "print(f\"Точность MultinomialNB: {lib_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
