{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSOLUTE_PATH = \"C:/Users/arman/it/prog/AI\"\n",
    "SEED = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sample:\n",
    "    def __init__(self, name: str, sample_func: Callable[[int], Sequence[int]]):\n",
    "        self.name = name\n",
    "        self.sample_func = sample_func\n",
    "\n",
    "all_samples = [\n",
    "    Sample(\n",
    "        name=\"uniform\", \n",
    "        sample_func=lambda size: scipy.stats.uniform.rvs(loc=5, scale=10, size=size, random_state=SEED), \n",
    "    ),\n",
    "    Sample(\n",
    "        name=\"bernoulli\", \n",
    "        sample_func=lambda size: scipy.stats.bernoulli.rvs(p=0.7, size=size, random_state=SEED),\n",
    "    ),\n",
    "    Sample(\n",
    "        name=\"binominal\", \n",
    "        sample_func=lambda size: scipy.stats.binom.rvs(n=20, p=0.6, size=size, random_state=SEED),\n",
    "    ),\n",
    "    Sample(\n",
    "        name=\"normal\",\n",
    "        sample_func=lambda size: scipy.stats.norm.rvs(loc=10, scale=2, size=size, random_state=SEED),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Estimator:\n",
    "    def __init__(self, name: str, estimator_func: Callable[[np.ndarray], int]):\n",
    "        self.name = name\n",
    "        self.estimator_func = estimator_func\n",
    "\n",
    "\n",
    "all_estimators = [\n",
    "    Estimator(name=\"loc\", estimator_func=lambda sample: np.min(sample)),\n",
    "    Estimator(name=\"scale\", estimator_func=lambda sample: np.max(sample) - np.min(sample)),\n",
    "    Estimator(name=\"p\", estimator_func=lambda sample: np.mean(sample)),\n",
    "    Estimator(name=\"std\", estimator_func=lambda sample: np.std(sample, ddof=1)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_value(\n",
    "    sample_array: Sequence[int],\n",
    "\testimator: Callable[[np.ndarray], int],\n",
    "    n_resamples: int = 1000\n",
    ") -> int:\n",
    "    # я не знаю какая генеральная совокупность,\n",
    "    # но чтобы приблизиться к правде, я сделаю оценку по совокупности\n",
    "    # из такого же количества выборок\n",
    "    sample = np.array(sample_array)\n",
    "    n = len(sample)\n",
    "    general_sample = np.array([])\n",
    "\n",
    "    for _ in range(n_resamples):\n",
    "        general_sample = np.concatenate((\n",
    "            general_sample,\n",
    "            np.random.choice(sample, size=n, replace=True)\n",
    "        ))\n",
    "    return estimator(general_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bootstrap(\n",
    "\tsample_array: Sequence[int],\n",
    "\testimator: Callable[[np.ndarray], int],\n",
    "\tconfidence_level: float = 0.95,\n",
    "\tn_resamples: int = 1000\n",
    ") -> tuple[int, int]:\n",
    "\n",
    "\tsample = np.array(sample_array)\n",
    "\n",
    "\tbootstrap_estimates = []\n",
    "\tn = len(sample)\n",
    "\n",
    "\tfor _ in range(n_resamples):\n",
    "\t\tbootstrap_sample = np.random.choice(sample, size=n, replace=True)\n",
    "\t\tbootstrap_estimates.append(estimator(bootstrap_sample))\n",
    "\n",
    "\talpha = 1 - confidence_level\n",
    "\tlower_percentile = alpha / 2 * 100\n",
    "\tupper_percentile = (1 - alpha / 2) * 100\n",
    "\n",
    "\tlower_bound = np.percentile(bootstrap_estimates, lower_percentile)\n",
    "\tupper_bound = np.percentile(bootstrap_estimates, upper_percentile)\n",
    "\n",
    "\treturn lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniform 100 loc\n",
      "uniform 100 scale\n",
      "uniform 100 p\n",
      "uniform 100 std\n",
      "bernoulli 100 loc\n",
      "bernoulli 100 scale\n",
      "bernoulli 100 p\n",
      "bernoulli 100 std\n",
      "binominal 100 loc\n",
      "binominal 100 scale\n",
      "binominal 100 p\n",
      "binominal 100 std\n",
      "normal 100 loc\n",
      "normal 100 scale\n",
      "normal 100 p\n",
      "normal 100 std\n",
      "uniform 1000 loc\n",
      "uniform 1000 scale\n",
      "uniform 1000 p\n",
      "uniform 1000 std\n",
      "bernoulli 1000 loc\n",
      "bernoulli 1000 scale\n",
      "bernoulli 1000 p\n",
      "bernoulli 1000 std\n",
      "binominal 1000 loc\n",
      "binominal 1000 scale\n",
      "binominal 1000 p\n",
      "binominal 1000 std\n",
      "normal 1000 loc\n",
      "normal 1000 scale\n",
      "normal 1000 p\n",
      "normal 1000 std\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for size in [100, 1000]:\n",
    "    for sample in all_samples:\n",
    "        for estimator in all_estimators:\n",
    "            true_value = get_true_value(\n",
    "                sample.sample_func(size),\n",
    "                estimator.estimator_func\n",
    "            )\n",
    "            my_lower_bound, my_upper_bound = my_bootstrap(\n",
    "                sample.sample_func(size),\n",
    "                estimator.estimator_func\n",
    "            )\n",
    "            scipy_result = scipy.stats.bootstrap(\n",
    "                (sample.sample_func(size),),\n",
    "                estimator.estimator_func\n",
    "            )\n",
    "            scipy_lower_bound = scipy_result.confidence_interval.low\n",
    "            scipy_upper_bound = scipy_result.confidence_interval.high\n",
    "            \n",
    "            data.append(dict(\n",
    "                sample_name=f\"{sample.name} {size}\",\n",
    "                estimator=estimator.name,\n",
    "                true_value=true_value,\n",
    "                my_lower_bound=my_lower_bound,\n",
    "                my_upper_bound=my_upper_bound,\n",
    "                scipy_lower_bound=scipy_lower_bound,\n",
    "                scipy_upper_bound=scipy_upper_bound\n",
    "            ))\n",
    "            print(f\"{sample.name} {size}\", estimator.name)\n",
    "\n",
    "with open(f'{ABSOLUTE_PATH}/dist/table.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=data[0].keys())\n",
    "\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
