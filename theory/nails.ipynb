{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvLayers(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ac9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = TwoConvLayers(in_channels=in_channels, out_channels=out_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        y = self.max_pool(x)\n",
    "        return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.transpose = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=2, stride=2)\n",
    "        self.block = TwoConvLayers(in_channels=in_channels, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.transpose(x)\n",
    "        u = torch.cat([x, y], dim=1)\n",
    "        u = self.block(u)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.enc_block1 = Encoder(in_channels=in_channels, out_channels=64)\n",
    "        self.enc_block2 = Encoder(in_channels=64, out_channels=128)\n",
    "        self.enc_block3 = Encoder(in_channels=128, out_channels=256)\n",
    "        self.enc_block4 = Encoder(in_channels=256, out_channels=512)\n",
    "\n",
    "        self.bottleneck = TwoConvLayers(in_channels=512, out_channels=1024)\n",
    "\n",
    "        self.dec_block1 = Decoder(in_channels=1024, out_channels=512)\n",
    "        self.dec_block2 = Decoder(in_channels=512, out_channels=256)\n",
    "        self.dec_block3 = Decoder(in_channels=256, out_channels=128)\n",
    "        self.dec_block4 = Decoder(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, y1 = self.enc_block1(x)\n",
    "        x, y2 = self.enc_block2(x)\n",
    "        x, y3 = self.enc_block3(x)\n",
    "        x, y4 = self.enc_block4(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.dec_block1(x, y4)\n",
    "        x = self.dec_block2(x, y3)\n",
    "        x = self.dec_block3(x, y2)\n",
    "        x = self.dec_block4(x, y1)\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NailsImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, valid_images, transform_img=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.valid_images = valid_images\n",
    "        self.transform_img = transform_img\n",
    "\n",
    "        images_path = os.path.join(self.folder_path, 'images')\n",
    "        masks_path = os.path.join(self.folder_path, 'labels')\n",
    "        self.images = [os.path.join(images_path, image) for image in self.valid_images]\n",
    "        self.masks = [os.path.join(masks_path, image) for image in self.valid_images]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, mask_path = self.images[index], self.masks[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        if self.transform_img is not None:\n",
    "            seed = np.random.randint(2147483647)\n",
    "            \n",
    "            torch.manual_seed(seed)\n",
    "            image = self.transform_img(image)\n",
    "            \n",
    "            torch.manual_seed(seed)\n",
    "            mask = self.transform_img(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b777b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(10, shear=(-5,5)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc616ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/matv864/it/AI_work/data/nails'\n",
    "images = os.listdir(os.path.join(data_folder, 'images'))\n",
    "random.shuffle(images)\n",
    "split_index = int(len(images) * 0.15)\n",
    "# increase the sample due to augmentations, \n",
    "# i.e. random augmentations will be applied to the data, \n",
    "# so repetitions are practically excluded\n",
    "train_images = images[split_index:]*2\n",
    "val_images = images[:split_index]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "\n",
    "val_dataset = NailsImageDataset(data_folder, val_images, transform_img=train_transformations)\n",
    "train_dataset = NailsImageDataset(data_folder, train_images, transform_img=train_transformations)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_data(image, mask):\n",
    "    if mask.dim() == 4:\n",
    "        mask = mask[0] \n",
    "        image = image[0]\n",
    "\n",
    "    if mask.dim() == 3 and mask.size(0) == 1:\n",
    "        mask = mask.squeeze(0) \n",
    "\n",
    "    image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(mask_np, cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in val_loader:\n",
    "    visualize_train_data(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth_coef=1):\n",
    "        super().__init__()\n",
    "        self.smooth_coef = smooth_coef\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        num = targets.size(0)\n",
    "        probs = nn.functional.sigmoid(logits)\n",
    "        x = probs.view(num, -1)\n",
    "        y = targets.view(num, -1)\n",
    "        intersection = x*y\n",
    "        sum_count_of_pixels = x.sum(1) + y.sum(1)\n",
    "        score = 2 * (intersection.sum(1) + self.smooth_coef) / (sum_count_of_pixels + self.smooth_coef)\n",
    "        return 1 - score.sum() / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_1 = nn.BCEWithLogitsLoss()\n",
    "criterion_2 = DiceLoss()\n",
    "EPOCH = 40\n",
    "lr_rate = 0.0001\n",
    "THRESHOLD = 0.5\n",
    "device = 'cuda:0'\n",
    "best_loss = float('inf')\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    print('\\nEpoch {}/{}'.format(epoch + 1, EPOCH))\n",
    "    print('=' * 100)\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    correct_train = 0  \n",
    "    total_train_pixels = 0  \n",
    "    for image, mask in train_loader:\n",
    "        image, mask = image.to(device), mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "\n",
    "        train_loss = criterion_1(outputs, mask) + criterion_2(outputs, mask)\n",
    "        total_train_loss += train_loss.item()\n",
    "\n",
    "        pred = (outputs > 0.5).float()\n",
    "\n",
    "        correct_train += (pred == mask).sum().item()\n",
    "        total_train_pixels += mask.numel() \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    average_train_loss = total_train_loss / len(train_loader)\n",
    "    average_train_accuracy = correct_train / total_train_pixels  \n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct_val = 0 \n",
    "    total_val_pixels = 0  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for image, mask in val_loader:\n",
    "            image, mask = image.to(device), mask.to(device)\n",
    "            outputs = model(image)\n",
    "\n",
    "            val_loss = criterion_1(outputs, mask) + criterion_2(outputs, mask)\n",
    "            total_val_loss += val_loss.item()\n",
    "\n",
    "            pred = (outputs > 0.5).float()\n",
    "\n",
    "            correct_val += (pred == mask).sum().item()\n",
    "            total_val_pixels += mask.numel() \n",
    "\n",
    "        average_val_loss = total_val_loss / len(val_loader)\n",
    "        average_val_accuracy = correct_val / total_val_pixels \n",
    "\n",
    "        if average_val_loss < best_loss:\n",
    "            best_loss = average_val_loss\n",
    "            torch.save(model.state_dict(), 'best_loss_unet.pt')\n",
    "\n",
    "    # In ra loss vÃ  accuracy\n",
    "    print(f\"Train Loss: {average_train_loss:.4f}, Train Accuracy: {average_train_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
