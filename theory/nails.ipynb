{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a305df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pynvml\n",
    "import gc\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e943ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "DEVICE = \"cuda:0\"\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd697bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoConvLayers(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ac9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = TwoConvLayers(in_channels=in_channels, out_channels=out_channels)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        y = self.max_pool(x)\n",
    "        return y, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.transpose = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels, kernel_size=2, stride=2)\n",
    "        self.block = TwoConvLayers(in_channels=in_channels, out_channels=out_channels)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x = self.transpose(x)\n",
    "        u = torch.cat([x, y], dim=1)\n",
    "        u = self.block(u)\n",
    "        return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a883ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.enc_block1 = Encoder(in_channels=in_channels, out_channels=64)\n",
    "        self.enc_block2 = Encoder(in_channels=64, out_channels=128)\n",
    "        self.enc_block3 = Encoder(in_channels=128, out_channels=256)\n",
    "        self.enc_block4 = Encoder(in_channels=256, out_channels=512)\n",
    "\n",
    "        self.bottleneck = TwoConvLayers(in_channels=512, out_channels=1024)\n",
    "\n",
    "        self.dec_block1 = Decoder(in_channels=1024, out_channels=512)\n",
    "        self.dec_block2 = Decoder(in_channels=512, out_channels=256)\n",
    "        self.dec_block3 = Decoder(in_channels=256, out_channels=128)\n",
    "        self.dec_block4 = Decoder(in_channels=128, out_channels=64)\n",
    "\n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, y1 = self.enc_block1(x)\n",
    "        x, y2 = self.enc_block2(x)\n",
    "        x, y3 = self.enc_block3(x)\n",
    "        x, y4 = self.enc_block4(x)\n",
    "\n",
    "        x = self.bottleneck(x)\n",
    "\n",
    "        x = self.dec_block1(x, y4)\n",
    "        x = self.dec_block2(x, y3)\n",
    "        x = self.dec_block3(x, y2)\n",
    "        x = self.dec_block4(x, y1)\n",
    "\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457d46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NailsImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, valid_images, transform_img):\n",
    "        self.folder_path = folder_path\n",
    "        self.valid_images = valid_images\n",
    "        self.transform_img = transform_img\n",
    "\n",
    "        images_path = os.path.join(self.folder_path, 'images')\n",
    "        masks_path = os.path.join(self.folder_path, 'labels')\n",
    "        \n",
    "        self.images = [os.path.join(images_path, image) for image in self.valid_images]\n",
    "        self.masks = [os.path.join(masks_path, image) for image in self.valid_images]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path, mask_path = self.images[index], self.masks[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        mask = Image.open(mask_path).convert('L')\n",
    "\n",
    "        seed = np.random.randint(2147483647)\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.transform_img(image)\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        mask = self.transform_img(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac64e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetForResult(Dataset):\n",
    "    def __init__(self, folder_path, transform_img):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform_img = transform_img\n",
    "\n",
    "        images_path = os.path.join(self.folder_path, 'my')\n",
    "        images = os.listdir(os.path.join(self.folder_path, 'my'))\n",
    "        self.images = [os.path.join(images_path, image) for image in images]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.images[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "        seed = np.random.randint(2147483647)\n",
    "\n",
    "        torch.manual_seed(seed)\n",
    "        image = self.transform_img(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b777b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_transformations = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(10, shear=(-5,5)),\n",
    "    transforms.ToTensor()])\n",
    "\n",
    "test_transformations = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc616ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/home/matv864/it/AI_work/data/nails'\n",
    "images = os.listdir(os.path.join(data_folder, 'images'))\n",
    "random.shuffle(images)\n",
    "split_index = int(len(images) * 0.15)\n",
    "\n",
    "train_images = images[split_index:]*2\n",
    "val_images = images[:split_index]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e462f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = NailsImageDataset(data_folder, val_images, transform_img=test_transformations)\n",
    "train_dataset = NailsImageDataset(data_folder, train_images, transform_img=train_transformations)\n",
    "personal_dataset = DatasetForResult(data_folder, test_transformations)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "personal_loader = DataLoader(personal_dataset, batch_size=1, shuffle=True)  # 1 - потому что чересчур маленький датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train_data(image, mask, predicted_mask=None):\n",
    "    if mask.dim() == 4:\n",
    "        mask = mask[0] \n",
    "        image = image[0]\n",
    "\n",
    "    if mask.dim() == 3 and mask.size(0) == 1:\n",
    "        mask = mask.squeeze(0)\n",
    "\n",
    "    image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "    mask_np = mask.cpu().numpy()\n",
    "    image_np = np.clip(image_np, 0, 1)\n",
    "    \n",
    "\n",
    "    images_counter = (2 if predicted_mask is None else 3)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "\n",
    "\n",
    "    plt.subplot(1, images_counter, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, images_counter, 2)\n",
    "    plt.imshow(mask_np, cmap='gray')\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if predicted_mask is not None:\n",
    "        if predicted_mask.dim() == 4:\n",
    "            predicted_mask = predicted_mask[0]  # Убираем batch-размер если есть\n",
    "        if predicted_mask.dim() == 3 and predicted_mask.shape[0] == 1:\n",
    "            predicted_mask = predicted_mask.squeeze(0)  # Убираем канал если 1\n",
    "        pred_np = predicted_mask.cpu().numpy()\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred_np, cmap='gray')\n",
    "        plt.title('Predicted Mask')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in val_loader:\n",
    "    visualize_train_data(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth_coef=1):\n",
    "        super().__init__()\n",
    "        self.smooth_coef = smooth_coef\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        num = targets.size(0)\n",
    "        probs = nn.functional.sigmoid(logits)\n",
    "        x = probs.view(num, -1)\n",
    "        y = targets.view(num, -1)\n",
    "        intersection = x*y\n",
    "        sum_count_of_pixels = x.sum(1) + y.sum(1)\n",
    "        score = 2 * (intersection.sum(1) + self.smooth_coef) / (sum_count_of_pixels + self.smooth_coef)\n",
    "        return 1 - score.sum() / num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949d8f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_1 = nn.BCEWithLogitsLoss()\n",
    "criterion_2 = DiceLoss()\n",
    "EPOCH = 40\n",
    "lr_rate = 0.0001\n",
    "THRESHOLD = 0.5\n",
    "best_loss = float('inf')\n",
    "model = UNet().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_rate)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08fdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCH):\n",
    "#     print('\\nEpoch {}/{}'.format(epoch + 1, EPOCH))\n",
    "#     print('=' * 100)\n",
    "#     model.train()\n",
    "#     total_train_loss = 0.0\n",
    "#     correct_train = 0  \n",
    "#     total_train_pixels = 0  \n",
    "#     for image, mask in train_loader:\n",
    "#         image, mask = image.to(DEVICE), mask.to(DEVICE)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(image)\n",
    "\n",
    "#         train_loss = criterion_1(outputs, mask) + criterion_2(outputs, mask)\n",
    "#         total_train_loss += train_loss.item()\n",
    "\n",
    "#         pred = (outputs > 0.5).float()\n",
    "\n",
    "#         correct_train += (pred == mask).sum().item()\n",
    "#         total_train_pixels += mask.numel() \n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#     average_train_loss = total_train_loss / len(train_loader)\n",
    "#     average_train_accuracy = correct_train / total_train_pixels  \n",
    "#     scheduler.step()\n",
    "\n",
    "#     model.eval()\n",
    "#     total_val_loss = 0.0\n",
    "#     correct_val = 0 \n",
    "#     total_val_pixels = 0  \n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for image, mask in val_loader:\n",
    "#             image, mask = image.to(DEVICE), mask.to(DEVICE)\n",
    "#             outputs = model(image)\n",
    "\n",
    "#             val_loss = criterion_1(outputs, mask) + criterion_2(outputs, mask)\n",
    "#             total_val_loss += val_loss.item()\n",
    "\n",
    "#             pred = (outputs > 0.5).float()\n",
    "\n",
    "#             correct_val += (pred == mask).sum().item()\n",
    "#             total_val_pixels += mask.numel() \n",
    "\n",
    "#         average_val_loss = total_val_loss / len(val_loader)\n",
    "#         average_val_accuracy = correct_val / total_val_pixels \n",
    "\n",
    "#         if average_val_loss < best_loss:\n",
    "#             best_loss = average_val_loss\n",
    "#             torch.save(model.state_dict(), 'best_loss_unet.pt')\n",
    "\n",
    "#     print(f\"Train Loss: {average_train_loss:.4f}, Train Accuracy: {average_train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = UNet().to(DEVICE)\n",
    "model.load_state_dict(torch.load('best_loss_unet.pt'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for target_image in personal_loader:\n",
    "        target_image = target_image.to(DEVICE)\n",
    "        output = model(target_image)\n",
    "        predicted_mask = torch.sigmoid(output)  # Преобразуем логиты в вероятности [0, 1]\n",
    "        predicted_mask = (predicted_mask > 0.5).float()\n",
    "        visualize_train_data(target_image, predicted_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813005d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for target_image, target_mask in val_loader:\n",
    "        target_image = target_image.to(DEVICE)\n",
    "        target_mask = target_mask.to(DEVICE)\n",
    "        output = model(target_image)\n",
    "        predicted_mask = torch.sigmoid(output)  # Преобразуем логиты в вероятности [0, 1]\n",
    "        predicted_mask = (predicted_mask > 0.5).float()\n",
    "        visualize_train_data(target_image, target_mask, predicted_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
